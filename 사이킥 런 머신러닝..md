# 학습/테스트 데이터 세트 분리 : train_test_split()

train_test_split() 의 파라미터
test_size : 전체 데이터 세트에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인지 결정, 기본값 : 0.25
train_size : 전체 데이터 세트에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인지 결정, test_size를 주로 사용해서 잘 쓰는 파라미터는 아님
shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지 결정, 기본값은 True, 데이터를 분산시켜 보다 효율적인 학습/테스트 데이터 세트를 만드는데 사용
random_state : 난수 값을 지정하면 여러번 다시 수행해도 동일한 결과가 나오게 해줌

# 2. 교차 검증(Cross Validation)

(1) K-Fold 교차검증(K-Fold Cross Validation)
K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증평가를 반복적으로 수행하는 방법

(2) Stratified KFold¶
불균형한(imbalanced) 분포도를 가진 레이블 데이터 집합을 위한 KFold 방식

--> 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배함

(3) cross_val_score() : 교차 검증을 보다 간단히게
앞서 수행한 Kfold로 데이터를 학습하고, 예측하는 코드를 보면 아래와 같은 프로세스로 검증이 진행되었음

(1) 폴드 세트 설정 
(2) for 루프 반복으로 학습 및 테스트 데이터의 인덱스를 추출 (3) 반복적으로 학습과 예측을 수행하고 예측수행을 반환

cross_val_score() 는 이 과정을 한꺼번에 수행해주는 API
cross_val_score() API의 선언형태
--> cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose =0, fit_params=None, pre_dispatch = '2*n_jobs')

estimator : 예측모델
X : 피처 데이터 세트
y : 레이블 데이터 세트,
scoring : 예측성능평가 지표
cv : 교차검증 폴드 수 (estimator로 classifier가 입력되면 Stratified Kfold 방식으로 학습/테스트 데이터 세트 분할)
수행 후 scoring 파라미터 값으로 지정된 성능 지표를 배열 형태로 반환

cross_val_score() API는 내부에서 estimator를 학습, 예측, 평가시켜주므로 간단히 교차검증을 수행할 수 있음
이와 유사하게 cross_validate() 은 여러개의 평가지표를 반환하며, 성능 평가지표와 수행시간도 같이 제공

(4) GridSearchCV - 교차검증과 하이퍼파라미터 튜닝을 한번에

GridSearch의 주요 파라미터
estimator : 적용 알고리즘 모델로 classifier, regressor, pipeline 등이 사용
param_grid : ket+리스트 값을 가지는 딕셔너리가 주어짐. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값을 지어
scoring : 예측 성능을 평가할 평가 방법을 지정, 문자열로 사이킷런의 성능평가 지표를 입력하나 별도의 함수 지정도 가능
refit : 기본값은 True이며 True로 생성시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파리미터로 재학습시킴
